{"version":3,"file":"crawlPreview.js","sourceRoot":"","sources":["../../../../src/controllers/v0/crawlPreview.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoBA,wDA2JC;AA9KD,kCAA2C;AAC3C,8CAAqD;AACrD,+EAA+E;AAC/E,+BAAoC;AACpC,oDAAiD;AACjD,8DAOsC;AACtC,iEAAgE;AAChE,8DAAiE;AACjE,qDAAuC;AACvC,uCAAsD;AACtD,+CAA4D;AAErD,KAAK,UAAU,sBAAsB,CAAC,GAAY,EAAE,GAAa;IACtE,IAAI,CAAC;QACH,MAAM,IAAI,GAAG,MAAM,IAAA,uBAAgB,EAAC,GAAG,EAAE,GAAG,EAAE,uBAAe,CAAC,OAAO,CAAC,CAAC;QAEvE,MAAM,UAAU,GAAG,CAAC,GAAG,CAAC,OAAO,CAAC,iBAAiB,CAAC;YAChD,GAAG,CAAC,MAAM,CAAC,aAAa,CAAW,CAAC;QACtC,MAAM,OAAO,GAAG,UAAU,GAAG,OAAO,CAAC,GAAG,CAAC,aAAa,CAAC;QACvD,MAAM,OAAO,GAAG,WAAW,OAAO,EAAE,CAAC;QAErC,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CAAC;YAClB,OAAO,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,KAAK,EAAE,CAAC,CAAC;QAC7D,CAAC;QAED,IAAI,IAAI,CAAC,KAAK,EAAE,KAAK,EAAE,QAAQ,EAAE,CAAC;YAChC,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,4HAA4H,EAAE,CAAC,CAAC;QACvK,CAAC;QAED,IAAI,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC;QACvB,IAAI,CAAC,GAAG,EAAE,CAAC;YACT,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,iBAAiB,EAAE,CAAC,CAAC;QAC5D,CAAC;QACD,IAAI,CAAC;YACH,GAAG,GAAG,IAAA,+BAAiB,EAAC,GAAG,CAAC,CAAC,GAAG,CAAC;QACnC,CAAC;QAAC,OAAO,CAAC,EAAE,CAAC;YACX,OAAO,GAAG;iBACP,MAAM,CAAC,CAAC,YAAY,KAAK,IAAI,CAAC,CAAC,OAAO,KAAK,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC;iBACrE,IAAI,CAAC,EAAE,KAAK,EAAE,CAAC,CAAC,OAAO,IAAI,CAAC,EAAE,CAAC,CAAC;QACrC,CAAC;QAED,IAAI,IAAA,wBAAY,EAAC,GAAG,EAAE,IAAI,CAAC,KAAK,EAAE,KAAK,IAAI,IAAI,CAAC,EAAE,CAAC;YACjD,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;gBAC1B,KAAK,EAAE,iCAAuB;aAC/B,CAAC,CAAC;QACL,CAAC;QAED,MAAM,cAAc,GAAG,GAAG,CAAC,IAAI,CAAC,cAAc,IAAI,EAAE,CAAC;QACrD,MAAM,WAAW,GAAG,GAAG,CAAC,IAAI,CAAC,WAAW,IAAI;YAC1C,eAAe,EAAE,KAAK;YACtB,WAAW,EAAE,KAAK;YAClB,UAAU,EAAE,EAAE;SACf,CAAC;QAEF,gFAAgF;QAChF,UAAU;QACV,8CAA8C;QAC9C,2BAA2B;QAC3B,yBAAyB;QACzB,6BAA6B;QAC7B,qBAAqB;QACrB,qEAAqE;QACrE,kCAAkC;QAClC,UAAU;QAEV,+DAA+D;QAC/D,6BAA6B;QAC7B,qCAAqC;QACrC,iCAAiC;QACjC,oCAAoC;QACpC,oDAAoD;QACpD,YAAY;QACZ,UAAU;QACV,wBAAwB;QACxB,uBAAuB;QACvB,yBAAyB;QACzB,UAAU;QACV,sBAAsB;QACtB,2BAA2B;QAC3B,6DAA6D;QAC7D,MAAM;QACN,IAAI;QAEJ,MAAM,EAAE,GAAG,IAAA,SAAM,GAAE,CAAC;QAEpB,IAAI,MAAM,CAAC;QAEX,IAAI,CAAC;YACH,MAAM,GAAG,MAAM,IAAI,CAAC,YAAY,EAAE,CAAC;QACrC,CAAC;QAAC,OAAO,CAAC,EAAE,CAAC,CAAA,CAAC;QAEd,MAAM,EAAE,aAAa,EAAE,eAAe,EAAE,GAAG,IAAA,+BAAuB,EAChE,WAAW,EACX,SAAS,EACT,SAAS,EACT,OAAO,CACR,CAAC;QAEF,MAAM,EAAE,GAAgB;YACtB,SAAS,EAAE,GAAG;YACd,cAAc;YACd,aAAa;YACb,eAAe;YACf,OAAO;YACP,MAAM;YACN,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE;SACtB,CAAC;QAEF,MAAM,IAAA,uBAAS,EAAC,EAAE,EAAE,EAAE,CAAC,CAAC;QAExB,MAAM,OAAO,GAAG,IAAA,4BAAc,EAAC,EAAE,EAAE,EAAE,EAAE,IAAI,CAAC,KAAK,EAAE,KAAK,IAAI,IAAI,CAAC,CAAC;QAElE,MAAM,IAAA,gCAAkB,EAAC,EAAE,CAAC,CAAC;QAE7B,MAAM,OAAO,GAAG,EAAE,CAAC,cAAc,EAAE,aAAa;YAC9C,CAAC,CAAC,CAAC;YACH,CAAC,CAAC,MAAM,OAAO,CAAC,aAAa,CAAC,KAAK,EAAE,IAAI,EAAE,EAAE;gBACzC,KAAK,MAAM,GAAG,IAAI,IAAI,EAAE,CAAC;oBACvB,MAAM,IAAA,qBAAO,EAAC,EAAE,EAAE,EAAE,EAAE,GAAG,CAAC,CAAC;oBAC3B,MAAM,KAAK,GAAG,IAAA,SAAM,GAAE,CAAC;oBACvB,MAAM,IAAA,yBAAY,EAChB;wBACE,GAAG;wBACH,IAAI,EAAE,aAAa;wBACnB,OAAO;wBACP,cAAc;wBACd,aAAa;wBACb,eAAe;wBACf,MAAM,EAAE,iBAAiB;wBACzB,QAAQ,EAAE,EAAE;wBACZ,UAAU,EAAE,IAAI;wBAChB,iBAAiB,EAAE,KAAK,EAAE,sBAAsB;qBACjD,EACD,EAAE,EACF,KAAK,CACN,CAAC;oBACF,MAAM,IAAA,yBAAW,EAAC,EAAE,EAAE,KAAK,EAAE,eAAM,CAAC,CAAC;gBACvC,CAAC;YACH,CAAC,CAAC,CAAC;QAEP,IAAI,OAAO,KAAK,CAAC,EAAE,CAAC;YAClB,MAAM,IAAA,qBAAO,EAAC,EAAE,EAAE,EAAE,EAAE,GAAG,CAAC,CAAC;YAC3B,MAAM,KAAK,GAAG,IAAA,SAAM,GAAE,CAAC;YACvB,MAAM,IAAA,yBAAY,EAChB;gBACE,GAAG;gBACH,IAAI,EAAE,aAAa;gBACnB,OAAO;gBACP,cAAc;gBACd,aAAa;gBACb,eAAe;gBACf,MAAM,EAAE,iBAAiB;gBACzB,QAAQ,EAAE,EAAE;gBACZ,iBAAiB,EAAE,KAAK,EAAE,sBAAsB;aACjD,EACD,EAAE,EACF,KAAK,CACN,CAAC;YACF,MAAM,IAAA,yBAAW,EAAC,EAAE,EAAE,KAAK,EAAE,eAAM,CAAC,CAAC;QACvC,CAAC;QAED,GAAG,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,EAAE,EAAE,CAAC,CAAC;IAC1B,CAAC;IAAC,OAAO,KAAK,EAAE,CAAC;QACf,MAAM,CAAC,gBAAgB,CAAC,KAAK,CAAC,CAAC;QAC/B,eAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;QACpB,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC;IACxD,CAAC;AACH,CAAC","sourcesContent":["import { Request, Response } from \"express\";\nimport { authenticateUser } from \"../auth\";\nimport { RateLimiterMode } from \"../../../src/types\";\nimport { isUrlBlocked } from \"../../../src/scraper/WebScraper/utils/blocklist\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport { logger } from \"../../../src/lib/logger\";\nimport {\n  addCrawlJob,\n  crawlToCrawler,\n  finishCrawlKickoff,\n  lockURL,\n  saveCrawl,\n  StoredCrawl,\n} from \"../../../src/lib/crawl-redis\";\nimport { addScrapeJob } from \"../../../src/services/queue-jobs\";\nimport { checkAndUpdateURL } from \"../../../src/lib/validateUrl\";\nimport * as Sentry from \"@sentry/node\";\nimport { fromLegacyScrapeOptions } from \"../v1/types\";\nimport { BLOCKLISTED_URL_MESSAGE } from \"../../lib/strings\";\n\nexport async function crawlPreviewController(req: Request, res: Response) {\n  try {\n    const auth = await authenticateUser(req, res, RateLimiterMode.Preview);\n\n    const incomingIP = (req.headers[\"x-forwarded-for\"] ||\n      req.socket.remoteAddress) as string;\n    const iptoken = incomingIP + process.env.PREVIEW_TOKEN;\n    const team_id = `preview_${iptoken}`;\n\n    if (!auth.success) {\n      return res.status(auth.status).json({ error: auth.error });\n    }\n    \n    if (auth.chunk?.flags?.forceZDR) {\n      return res.status(400).json({ error: \"Your team has zero data retention enabled. This is not supported on the v0 API. Please update your code to use the v1 API.\" });\n    }\n\n    let url = req.body.url;\n    if (!url) {\n      return res.status(400).json({ error: \"Url is required\" });\n    }\n    try {\n      url = checkAndUpdateURL(url).url;\n    } catch (e) {\n      return res\n        .status(e instanceof Error && e.message === \"Invalid URL\" ? 400 : 500)\n        .json({ error: e.message ?? e });\n    }\n\n    if (isUrlBlocked(url, auth.chunk?.flags ?? null)) {\n      return res.status(403).json({\n        error: BLOCKLISTED_URL_MESSAGE,\n      });\n    }\n\n    const crawlerOptions = req.body.crawlerOptions ?? {};\n    const pageOptions = req.body.pageOptions ?? {\n      onlyMainContent: false,\n      includeHtml: false,\n      removeTags: [],\n    };\n\n    // if (mode === \"single_urls\" && !url.includes(\",\")) { // NOTE: do we need this?\n    //   try {\n    //     const a = new WebScraperDataProvider();\n    //     await a.setOptions({\n    //       jobId: uuidv4(),\n    //       mode: \"single_urls\",\n    //       urls: [url],\n    //       crawlerOptions: { ...crawlerOptions, returnOnlyUrls: true },\n    //       pageOptions: pageOptions,\n    //     });\n\n    //     const docs = await a.getDocuments(false, (progress) => {\n    //       job.updateProgress({\n    //         current: progress.current,\n    //         total: progress.total,\n    //         current_step: \"SCRAPING\",\n    //         current_url: progress.currentDocumentUrl,\n    //       });\n    //     });\n    //     return res.json({\n    //       success: true,\n    //       documents: docs,\n    //     });\n    //   } catch (error) {\n    //     logger.error(error);\n    //     return res.status(500).json({ error: error.message });\n    //   }\n    // }\n\n    const id = uuidv4();\n\n    let robots;\n\n    try {\n      robots = await this.getRobotsTxt();\n    } catch (_) {}\n\n    const { scrapeOptions, internalOptions } = fromLegacyScrapeOptions(\n      pageOptions,\n      undefined,\n      undefined,\n      team_id\n    );\n\n    const sc: StoredCrawl = {\n      originUrl: url,\n      crawlerOptions,\n      scrapeOptions,\n      internalOptions,\n      team_id,\n      robots,\n      createdAt: Date.now(),\n    };\n\n    await saveCrawl(id, sc);\n\n    const crawler = crawlToCrawler(id, sc, auth.chunk?.flags ?? null);\n\n    await finishCrawlKickoff(id);\n\n    const sitemap = sc.crawlerOptions?.ignoreSitemap\n      ? 0\n      : await crawler.tryGetSitemap(async (urls) => {\n          for (const url of urls) {\n            await lockURL(id, sc, url);\n            const jobId = uuidv4();\n            await addScrapeJob(\n              {\n                url,\n                mode: \"single_urls\",\n                team_id,\n                crawlerOptions,\n                scrapeOptions,\n                internalOptions,\n                origin: \"website-preview\",\n                crawl_id: id,\n                sitemapped: true,\n                zeroDataRetention: false, // not supported on v0\n              },\n              {},\n              jobId,\n            );\n            await addCrawlJob(id, jobId, logger);\n          }\n        });\n\n    if (sitemap === 0) {\n      await lockURL(id, sc, url);\n      const jobId = uuidv4();\n      await addScrapeJob(\n        {\n          url,\n          mode: \"single_urls\",\n          team_id,\n          crawlerOptions,\n          scrapeOptions,\n          internalOptions,\n          origin: \"website-preview\",\n          crawl_id: id,\n          zeroDataRetention: false, // not supported on v0\n        },\n        {},\n        jobId,\n      );\n      await addCrawlJob(id, jobId, logger);\n    }\n\n    res.json({ jobId: id });\n  } catch (error) {\n    Sentry.captureException(error);\n    logger.error(error);\n    return res.status(500).json({ error: error.message });\n  }\n}\n"]}