{"version":3,"file":"batch-scrape.js","sourceRoot":"","sources":["../../../../src/controllers/v1/batch-scrape.ts"],"names":[],"mappings":";;AA2BA,sDA+KC;AAzMD,+BAAoC;AACpC,mCAQiB;AACjB,uDAO+B;AAC/B,gEAA4D;AAC5D,yDAAwD;AACxD,0DAA0D;AAC1D,oDAAqD;AACrD,6CAAqD;AACrD,+CAA4D;AAC5D,wEAAwE;AAEjE,KAAK,UAAU,qBAAqB,CACzC,GAAiE,EACjE,GAAkC;IAElC,MAAM,iBAAiB,GAAG,EAAE,GAAG,GAAG,CAAC,IAAI,EAAE,CAAC;IAE1C,IAAI,GAAG,CAAC,IAAI,CAAC,iBAAiB,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,KAAK,EAAE,QAAQ,EAAE,CAAC;QAC7D,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;YAC1B,OAAO,EAAE,KAAK;YACd,KAAK,EAAE,iHAAiH;SACzH,CAAC,CAAC;IACL,CAAC;IAED,MAAM,iBAAiB,GAAG,GAAG,CAAC,IAAI,EAAE,KAAK,EAAE,QAAQ,IAAI,GAAG,CAAC,IAAI,CAAC,iBAAiB,CAAC;IAElF,IAAI,GAAG,CAAC,IAAI,EAAE,iBAAiB,KAAK,IAAI,EAAE,CAAC;QACzC,GAAG,CAAC,IAAI,GAAG,+CAAuC,CAAC,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACrE,CAAC;SAAM,CAAC;QACN,GAAG,CAAC,IAAI,GAAG,gCAAwB,CAAC,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IACtD,CAAC;IAED,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,UAAU,IAAI,IAAA,SAAM,GAAE,CAAC;IAC3C,MAAM,MAAM,GAAG,eAAO,CAAC,KAAK,CAAC;QAC3B,OAAO,EAAE,EAAE;QACX,aAAa,EAAE,EAAE;QACjB,MAAM,EAAE,QAAQ;QAChB,MAAM,EAAE,uBAAuB;QAC/B,MAAM,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;QACxB,iBAAiB;KAClB,CAAC,CAAC;IAEH,IAAI,IAAI,GAAa,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC;IACnC,IAAI,gBAAgB,GAAG,iBAAiB,CAAC,IAAI,CAAC;IAC9C,IAAI,WAAW,GAAyB,SAAS,CAAC;IAElD,IAAI,GAAG,CAAC,IAAI,CAAC,iBAAiB,EAAE,CAAC;QAC/B,WAAW,GAAG,EAAE,CAAC;QAEjB,IAAI,WAAW,GAAG,IAAI,CAAC;QACvB,IAAI,GAAG,EAAE,CAAC;QACV,gBAAgB,GAAG,EAAE,CAAC;QACtB,KAAK,MAAM,CAAC,IAAI,WAAW,EAAE,CAAC;YAC5B,IAAI,CAAC;gBACH,MAAM,EAAE,GAAG,WAAS,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;gBAC9B,IAAI,CAAC,IAAA,wBAAY,EAAC,EAAE,EAAE,GAAG,CAAC,IAAI,EAAE,KAAK,IAAI,IAAI,CAAC,EAAE,CAAC;oBAC/C,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;oBACd,gBAAgB,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;gBAC3B,CAAC;qBAAM,CAAC;oBACN,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;gBACtB,CAAC;YACH,CAAC;YAAC,OAAO,CAAC,EAAE,CAAC;gBACX,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACtB,CAAC;QACH,CAAC;IACH,CAAC;SAAM,CAAC;QACN,IAAI,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,GAAW,EAAE,EAAE,CAAC,IAAA,wBAAY,EAAC,GAAG,EAAE,GAAG,CAAC,IAAI,EAAE,KAAK,IAAI,IAAI,CAAC,CAAC,EAAE,CAAC;YACrF,IAAI,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACrB,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;oBAC1B,OAAO,EAAE,KAAK;oBACd,KAAK,EAAE,iCAAuB;iBAC/B,CAAC,CAAC;YACL,CAAC;QACH,CAAC;IACH,CAAC;IAED,MAAM,CAAC,KAAK,CAAC,eAAe,GAAG,EAAE,GAAG,WAAW,EAAE;QAC/C,UAAU,EAAE,IAAI,CAAC,MAAM;QACvB,UAAU,EAAE,GAAG,CAAC,IAAI,CAAC,UAAU;QAC/B,OAAO,EAAE,GAAG,CAAC,OAAO;KACrB,CAAC,CAAC;IAEH,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,UAAU,EAAE,CAAC;QACzB,MAAM,IAAA,oBAAQ,EAAC,EAAE,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;IACvC,CAAC;IAED,MAAM,EAAE,GAAgB,GAAG,CAAC,IAAI,CAAC,UAAU;QACzC,CAAC,CAAE,CAAC,MAAM,IAAA,sBAAQ,EAAC,GAAG,CAAC,IAAI,CAAC,UAAU,CAAC,CAAiB;QACxD,CAAC,CAAC;YACE,cAAc,EAAE,IAAI;YACpB,aAAa,EAAE,GAAG,CAAC,IAAI;YACvB,eAAe,EAAE;gBACf,qBAAqB,EAAE,IAAI;gBAC3B,MAAM,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;gBACxB,qBAAqB,EAAE,OAAO,CAAC,GAAG,CAAC,2BAA2B,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK;gBAC7E,iBAAiB;aAClB,EAAE,iGAAiG;YACpG,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE;YACrB,cAAc,EAAE,GAAG,CAAC,IAAI,CAAC,cAAc;YACvC,iBAAiB;SAClB,CAAC;IAEN,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,UAAU,EAAE,CAAC;QACzB,MAAM,IAAA,uBAAS,EAAC,EAAE,EAAE,EAAE,CAAC,CAAC;IAC1B,CAAC;IAED,IAAI,WAAW,GAAG,EAAE,CAAC;IAErB,uDAAuD;IACvD,kDAAkD;IAClD,IAAI,IAAI,CAAC,MAAM,GAAG,IAAI,EAAE,CAAC;QACvB,iBAAiB;QACjB,WAAW,GAAG,MAAM,IAAA,6BAAc,EAAC;YACjC,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,YAAY,EAAE,EAAE;SACjB,CAAC,CAAC;IACL,CAAC;IACD,MAAM,CAAC,KAAK,CAAC,qBAAqB,GAAG,WAAW,EAAE,EAAE,WAAW,EAAE,CAAC,CAAC;IAEnE,MAAM,aAAa,GAAkB,EAAE,GAAG,GAAG,CAAC,IAAI,EAAE,CAAC;IACrD,OAAQ,aAAqB,CAAC,IAAI,CAAC;IACnC,OAAQ,aAAqB,CAAC,UAAU,CAAC;IAEzC,MAAM,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;QACxB,IAAI,EAAE;YACJ,GAAG,EAAE,CAAC;YACN,IAAI,EAAE,aAAsB;YAC5B,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,cAAc,EAAE,IAAI;YACpB,aAAa;YACb,MAAM,EAAE,KAAK;YACb,WAAW,EAAE,GAAG,CAAC,IAAI,CAAC,WAAW;YACjC,QAAQ,EAAE,EAAE;YACZ,UAAU,EAAE,IAAI;YAChB,EAAE,EAAE,IAAI;YACR,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,eAAe,EAAE,EAAE,CAAC,eAAe;YACnC,iBAAiB;SAClB;QACD,IAAI,EAAE;YACJ,KAAK,EAAE,IAAA,SAAM,GAAE;YACf,QAAQ,EAAE,EAAE;SACb;KACJ,CAAC,CAAC,CAAC;IAEJ,MAAM,IAAA,gCAAkB,EAAC,EAAE,CAAC,CAAC;IAE7B,MAAM,CAAC,KAAK,CAAC,iBAAiB,CAAC,CAAC;IAChC,MAAM,IAAA,sBAAQ,EACZ,EAAE,EACF,EAAE,EACF,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,EAC3B,MAAM,CACP,CAAC;IACF,MAAM,CAAC,KAAK,CAAC,gCAAgC,CAAC,CAAC;IAC/C,MAAM,IAAA,0BAAY,EAChB,EAAE,EACF,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,EAC7B,MAAM,CACP,CAAC;IACF,MAAM,CAAC,KAAK,CAAC,iCAAiC,CAAC,CAAC;IAChD,MAAM,IAAA,0BAAa,EAAC,IAAI,CAAC,CAAC;IAE1B,IAAI,GAAG,CAAC,IAAI,CAAC,OAAO,EAAE,CAAC;QACrB,MAAM,CAAC,KAAK,CAAC,8CAA8C,EAAE;YAC3D,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;SAC1B,CAAC,CAAC;QACH,MAAM,IAAA,qBAAW,EAAC;YAChB,MAAM,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACxB,OAAO,EAAE,EAAE;YACX,IAAI,EAAE,IAAI;YACV,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;YACzB,EAAE,EAAE,IAAI;YACR,SAAS,EAAE,sBAAsB;SAClC,CAAC,CAAC;IACL,CAAC;IAED,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,CAAC,GAAG,KAAK,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,OAAO,CAAC;IAEtE,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;QAC1B,OAAO,EAAE,IAAI;QACb,EAAE;QACF,GAAG,EAAE,GAAG,QAAQ,MAAM,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,oBAAoB,EAAE,EAAE;QAC7D,WAAW;KACZ,CAAC,CAAC;AACL,CAAC","sourcesContent":["import { Response } from \"express\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport {\n  BatchScrapeRequest,\n  batchScrapeRequestSchema,\n  batchScrapeRequestSchemaNoURLValidation,\n  url as urlSchema,\n  RequestWithAuth,\n  ScrapeOptions,\n  BatchScrapeResponse,\n} from \"./types\";\nimport {\n  addCrawlJobs,\n  finishCrawlKickoff,\n  getCrawl,\n  lockURLs,\n  saveCrawl,\n  StoredCrawl,\n} from \"../../lib/crawl-redis\";\nimport { logCrawl } from \"../../services/logging/crawl_log\";\nimport { getJobPriority } from \"../../lib/job-priority\";\nimport { addScrapeJobs } from \"../../services/queue-jobs\";\nimport { callWebhook } from \"../../services/webhook\";\nimport { logger as _logger } from \"../../lib/logger\";\nimport { BLOCKLISTED_URL_MESSAGE } from \"../../lib/strings\";\nimport { isUrlBlocked } from \"../../scraper/WebScraper/utils/blocklist\";  \n\nexport async function batchScrapeController(\n  req: RequestWithAuth<{}, BatchScrapeResponse, BatchScrapeRequest>,\n  res: Response<BatchScrapeResponse>,\n) {\n  const preNormalizedBody = { ...req.body };\n\n  if (req.body.zeroDataRetention && !req.acuc?.flags?.allowZDR) {\n    return res.status(400).json({\n      success: false,\n      error: \"Zero data retention is enabled for this team. If you're interested in ZDR, please contact support@firecrawl.com\",\n    });\n  }\n  \n  const zeroDataRetention = req.acuc?.flags?.forceZDR || req.body.zeroDataRetention;\n\n  if (req.body?.ignoreInvalidURLs === true) {\n    req.body = batchScrapeRequestSchemaNoURLValidation.parse(req.body);\n  } else {\n    req.body = batchScrapeRequestSchema.parse(req.body);\n  }\n\n  const id = req.body.appendToId ?? uuidv4();\n  const logger = _logger.child({\n    crawlId: id,\n    batchScrapeId: id,\n    module: \"api/v1\",\n    method: \"batchScrapeController\",\n    teamId: req.auth.team_id,\n    zeroDataRetention,\n  });\n\n  let urls: string[] = req.body.urls;\n  let unnormalizedURLs = preNormalizedBody.urls;\n  let invalidURLs: string[] | undefined = undefined;\n\n  if (req.body.ignoreInvalidURLs) {\n    invalidURLs = [];\n\n    let pendingURLs = urls;\n    urls = [];\n    unnormalizedURLs = [];\n    for (const u of pendingURLs) {\n      try {\n        const nu = urlSchema.parse(u);\n        if (!isUrlBlocked(nu, req.acuc?.flags ?? null)) {\n          urls.push(nu);\n          unnormalizedURLs.push(u);\n        } else {\n          invalidURLs.push(u);\n        }\n      } catch (_) {\n        invalidURLs.push(u);\n      }\n    }\n  } else {\n    if (req.body.urls?.some((url: string) => isUrlBlocked(url, req.acuc?.flags ?? null))) {\n      if (!res.headersSent) {\n        return res.status(403).json({\n          success: false,\n          error: BLOCKLISTED_URL_MESSAGE,\n        });\n      }\n    }\n  }\n\n  logger.debug(\"Batch scrape \" + id + \" starting\", {\n    urlsLength: urls.length,\n    appendToId: req.body.appendToId,\n    account: req.account,\n  });\n\n  if (!req.body.appendToId) {\n    await logCrawl(id, req.auth.team_id);\n  }\n\n  const sc: StoredCrawl = req.body.appendToId\n    ? ((await getCrawl(req.body.appendToId)) as StoredCrawl)\n    : {\n        crawlerOptions: null,\n        scrapeOptions: req.body,\n        internalOptions: {\n          disableSmartWaitCache: true,\n          teamId: req.auth.team_id,\n          saveScrapeResultToGCS: process.env.GCS_FIRE_ENGINE_BUCKET_NAME ? true : false,\n          zeroDataRetention,\n        }, // NOTE: smart wait disabled for batch scrapes to ensure contentful scrape, speed does not matter\n        team_id: req.auth.team_id,\n        createdAt: Date.now(),\n        maxConcurrency: req.body.maxConcurrency,\n        zeroDataRetention,\n      };\n\n  if (!req.body.appendToId) {\n    await saveCrawl(id, sc);\n  }\n\n  let jobPriority = 20;\n\n  // If it is over 1000, we need to get the job priority,\n  // otherwise we can use the default priority of 20\n  if (urls.length > 1000) {\n    // set base to 21\n    jobPriority = await getJobPriority({\n      team_id: req.auth.team_id,\n      basePriority: 21,\n    });\n  }\n  logger.debug(\"Using job priority \" + jobPriority, { jobPriority });\n\n  const scrapeOptions: ScrapeOptions = { ...req.body };\n  delete (scrapeOptions as any).urls;\n  delete (scrapeOptions as any).appendToId;\n\n  const jobs = urls.map(x => ({\n      data: {\n        url: x,\n        mode: \"single_urls\" as const,\n        team_id: req.auth.team_id,\n        crawlerOptions: null,\n        scrapeOptions,\n        origin: \"api\",\n        integration: req.body.integration,\n        crawl_id: id,\n        sitemapped: true,\n        v1: true,\n        webhook: req.body.webhook,\n        internalOptions: sc.internalOptions,\n        zeroDataRetention,\n      },\n      opts: {\n        jobId: uuidv4(),\n        priority: 20,\n      },\n  }));\n\n  await finishCrawlKickoff(id);\n\n  logger.debug(\"Locking URLs...\");\n  await lockURLs(\n    id,\n    sc,\n    jobs.map((x) => x.data.url),\n    logger,\n  );\n  logger.debug(\"Adding scrape jobs to Redis...\");\n  await addCrawlJobs(\n    id,\n    jobs.map((x) => x.opts.jobId),\n    logger,\n  );\n  logger.debug(\"Adding scrape jobs to BullMQ...\");\n  await addScrapeJobs(jobs);\n\n  if (req.body.webhook) {\n    logger.debug(\"Calling webhook with batch_scrape.started...\", {\n      webhook: req.body.webhook,\n    });\n    await callWebhook({\n      teamId: req.auth.team_id,\n      crawlId: id,\n      data: null,\n      webhook: req.body.webhook,\n      v1: true,\n      eventType: \"batch_scrape.started\",\n    });\n  }\n\n  const protocol = process.env.ENV === \"local\" ? req.protocol : \"https\";\n\n  return res.status(200).json({\n    success: true,\n    id,\n    url: `${protocol}://${req.get(\"host\")}/v1/batch/scrape/${id}`,\n    invalidURLs,\n  });\n}\n"]}