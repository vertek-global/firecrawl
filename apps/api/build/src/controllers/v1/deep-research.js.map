{"version":3,"file":"deep-research.js","sourceRoot":"","sources":["../../../../src/controllers/v1/deep-research.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4CA,wDAkEC;AA7GD,mCAAyE;AACzE,gEAAoE;AACpE,qDAAuC;AACvC,qFAA+E;AAC/E,6BAAwB;AAEX,QAAA,yBAAyB,GAAG,OAAC,CAAC,MAAM,CAAC;IAChD,KAAK,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,QAAQ,CAAC,kCAAkC,CAAC,CAAC,QAAQ,EAAE;IACzE,QAAQ,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,sCAAsC,CAAC;IAC/F,OAAO,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,mCAAmC,CAAC;IAC9F,SAAS,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,QAAQ,CAAC,uBAAuB,CAAC;IACrF,cAAc,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,QAAQ,CAAC,0CAA0C,CAAC,CAAC,QAAQ,EAAE;IAC1F,YAAY,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,QAAQ,CAAC,iDAAiD,CAAC,CAAC,QAAQ,EAAE;IAC/F,OAAO,EAAE,OAAC,CAAC,KAAK,CAAC,OAAC,CAAC,IAAI,CAAC,CAAC,UAAU,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,UAAU,CAAC,CAAC;IACpE,gCAAgC;IAChC,KAAK,EAAE,OAAC,CAAC,MAAM,EAAE,CAAC,QAAQ,CAAC,mCAAmC,CAAC,CAAC,QAAQ,EAAE;IAC1E,WAAW,EAAE,sBAAc,CAAC,QAAQ,EAAE;CACvC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,KAAK,EAAE;IAC1C,OAAO,EAAE,wCAAwC;CAClD,CAAC,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,EAAE;IAChB,MAAM,aAAa,GAAG,GAAG,CAAC,OAAO,EAAE,QAAQ,CAAC,MAAM,CAAC,CAAC;IACpD,MAAM,cAAc,GAAG,GAAG,CAAC,WAAW,KAAK,SAAS,CAAC;IACrD,OAAO,CAAC,aAAa,IAAI,cAAc,CAAC,IAAI,CAAC,CAAC,aAAa,IAAI,CAAC,cAAc,CAAC,CAAC;AAClF,CAAC,EAAE;IACD,OAAO,EAAE,+EAA+E;CACzF,CAAC,CAAC,SAAS,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;IACpB,GAAG,IAAI;IACP,KAAK,EAAE,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,KAAK,CAAC,iCAAiC;CAClE,CAAC,CAAC,CAAC;AASJ;;;;;GAKG;AACI,KAAK,UAAU,sBAAsB,CAC1C,GAAmE,EACnE,GAAmC;IAEnC,IAAI,GAAG,CAAC,IAAI,EAAE,KAAK,EAAE,QAAQ,EAAE,CAAC;QAC9B,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,kJAAkJ,EAAE,CAAC,CAAC;IAC7M,CAAC;IAED,GAAG,CAAC,IAAI,GAAG,iCAAyB,CAAC,KAAK,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC;IAErD,MAAM,UAAU,GAAG,MAAM,CAAC,UAAU,EAAE,CAAC;IACvC,MAAM,OAAO,GAAG;QACd,OAAO,EAAE,GAAG,CAAC,IAAI;QACjB,MAAM,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;QACxB,KAAK,EAAE,GAAG,CAAC,IAAI,EAAE,MAAM;QACvB,UAAU;KACX,CAAC;IAEF,MAAM,IAAA,sCAAgB,EAAC,UAAU,EAAE;QACjC,EAAE,EAAE,UAAU;QACd,OAAO,EAAE,GAAG,CAAC,IAAI,CAAC,OAAO;QACzB,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE;QACrB,MAAM,EAAE,YAAY;QACpB,YAAY,EAAE,CAAC;QACf,QAAQ,EAAE,GAAG,CAAC,IAAI,CAAC,QAAQ;QAC3B,cAAc,EAAE,CAAC;QACjB,kBAAkB,EAAE,GAAG,CAAC,IAAI,CAAC,QAAQ,GAAG,CAAC,EAAE,0BAA0B;QACrE,QAAQ,EAAE,EAAE;QACZ,OAAO,EAAE,EAAE;QACX,UAAU,EAAE,EAAE;QACd,SAAS,EAAE,EAAE;KACd,CAAC,CAAC;IAEH,IAAI,MAAM,CAAC,aAAa,EAAE,EAAE,CAAC;QAC3B,MAAM,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC;QAC5C,MAAM,MAAM,CAAC,SAAS,CACpB;YACE,IAAI,EAAE,uBAAuB;YAC7B,EAAE,EAAE,eAAe;YACnB,UAAU,EAAE;gBACV,sBAAsB,EAAE,UAAU;gBAClC,4BAA4B,EAAE,IAAA,oCAAoB,GAAE,CAAC,IAAI;gBACzD,6BAA6B,EAAE,IAAI;aACpC;SACF,EACD,KAAK,EAAE,IAAI,EAAE,EAAE;YACb,MAAM,IAAA,oCAAoB,GAAE,CAAC,GAAG,CAAC,UAAU,EAAE;gBAC3C,GAAG,OAAO;gBACV,MAAM,EAAE;oBACN,KAAK,EAAE,MAAM,CAAC,iBAAiB,CAAC,IAAI,CAAC;oBACrC,OAAO,EAAE,MAAM,CAAC,mBAAmB,CAAC,IAAI,CAAC;oBACzC,IAAI;iBACL;aACF,EAAE,EAAE,KAAK,EAAE,UAAU,EAAE,CAAC,CAAC;QAC5B,CAAC,CACF,CAAC;IACJ,CAAC;SAAM,CAAC;QACN,MAAM,IAAA,oCAAoB,GAAE,CAAC,GAAG,CAAC,UAAU,EAAE,OAAO,EAAE;YACpD,KAAK,EAAE,UAAU;SAClB,CAAC,CAAC;IACL,CAAC;IAED,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;QAC1B,OAAO,EAAE,IAAI;QACb,EAAE,EAAE,UAAU;KACf,CAAC,CAAC;AACL,CAAC","sourcesContent":["import { Request, Response } from \"express\";\nimport { ErrorResponse, extractOptions, RequestWithAuth } from \"./types\";\nimport { getDeepResearchQueue } from \"../../services/queue-service\";\nimport * as Sentry from \"@sentry/node\";\nimport { saveDeepResearch } from \"../../lib/deep-research/deep-research-redis\";\nimport { z } from \"zod\";\n\nexport const deepResearchRequestSchema = z.object({\n  query: z.string().describe('The query or topic to search for').optional(),\n  maxDepth: z.number().min(1).max(12).default(7).describe('Maximum depth of research iterations'),\n  maxUrls: z.number().min(1).max(1000).default(20).describe('Maximum number of URLs to analyze'),\n  timeLimit: z.number().min(30).max(600).default(300).describe('Time limit in seconds'),\n  analysisPrompt: z.string().describe('The prompt to use for the final analysis').optional(),\n  systemPrompt: z.string().describe('The system prompt to use for the research agent').optional(),\n  formats: z.array(z.enum(['markdown', 'json'])).default(['markdown']),\n  // @deprecated Use query instead\n  topic: z.string().describe('The topic or question to research').optional(),\n  jsonOptions: extractOptions.optional(),\n}).refine(data => data.query || data.topic, {\n  message: \"Either query or topic must be provided\"\n}).refine((obj) => {\n  const hasJsonFormat = obj.formats?.includes(\"json\");\n  const hasJsonOptions = obj.jsonOptions !== undefined;\n  return (hasJsonFormat && hasJsonOptions) || (!hasJsonFormat && !hasJsonOptions);\n}, {\n  message: \"When 'json' format is specified, jsonOptions must be provided, and vice versa\"\n}).transform(data => ({\n  ...data,\n  query: data.topic || data.query // Use topic as query if provided\n}));\n\nexport type DeepResearchRequest = z.infer<typeof deepResearchRequestSchema>;\n\nexport type DeepResearchResponse = ErrorResponse | {\n  success: boolean;\n  id: string;\n};\n\n/**\n * Initiates a deep research job based on the provided topic.\n * @param req - The request object containing authentication and research parameters.\n * @param res - The response object to send the research job ID.\n * @returns A promise that resolves when the research job is queued.\n */\nexport async function deepResearchController(\n  req: RequestWithAuth<{}, DeepResearchResponse, DeepResearchRequest>,\n  res: Response<DeepResearchResponse>,\n) {\n  if (req.acuc?.flags?.forceZDR) {\n    return res.status(400).json({ success: false, error: \"Your team has zero data retention enabled. This is not supported on deep research. Please contact support@firecrawl.com to unblock this feature.\" });\n  }\n\n  req.body = deepResearchRequestSchema.parse(req.body);\n\n  const researchId = crypto.randomUUID();\n  const jobData = {\n    request: req.body,\n    teamId: req.auth.team_id,\n    subId: req.acuc?.sub_id,\n    researchId,\n  };\n\n  await saveDeepResearch(researchId, {\n    id: researchId,\n    team_id: req.auth.team_id,\n    createdAt: Date.now(),\n    status: \"processing\",\n    currentDepth: 0,\n    maxDepth: req.body.maxDepth,\n    completedSteps: 0,\n    totalExpectedSteps: req.body.maxDepth * 5, // 5 steps per depth level\n    findings: [],\n    sources: [],\n    activities: [],\n    summaries: [],\n  });\n\n  if (Sentry.isInitialized()) {\n    const size = JSON.stringify(jobData).length;\n    await Sentry.startSpan(\n      {\n        name: \"Add deep research job\",\n        op: \"queue.publish\",\n        attributes: {\n          \"messaging.message.id\": researchId,\n          \"messaging.destination.name\": getDeepResearchQueue().name,\n          \"messaging.message.body.size\": size,\n        },\n      },\n      async (span) => {\n        await getDeepResearchQueue().add(researchId, {\n          ...jobData,\n          sentry: {\n            trace: Sentry.spanToTraceHeader(span),\n            baggage: Sentry.spanToBaggageHeader(span),\n            size,\n          },\n        }, { jobId: researchId });\n      },\n    );\n  } else {\n    await getDeepResearchQueue().add(researchId, jobData, {\n      jobId: researchId,\n    });\n  }\n\n  return res.status(200).json({\n    success: true,\n    id: researchId,\n  });\n}\n"]}