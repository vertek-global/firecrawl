{"version":3,"file":"crawl.test.js","sourceRoot":"","sources":["../../../../src/__tests__/snips/crawl.test.ts"],"names":[],"mappings":";;AAAA,+BAAiH;AACjH,2CAAqD;AAErD,IAAI,QAAkB,CAAC;AAEvB,SAAS,CAAC,KAAK,IAAI,EAAE;IACnB,QAAQ,GAAG,MAAM,IAAA,WAAK,EAAC;QACrB,IAAI,EAAE,OAAO;QACb,WAAW,EAAE,GAAG;QAChB,OAAO,EAAE,OAAO;KACjB,CAAC,CAAC;AACL,CAAC,EAAE,KAAK,CAAC,CAAC;AAEV,IAAA,kBAAQ,EAAC,aAAa,EAAE,GAAG,EAAE;IACzB,YAAE,CAAC,UAAU,CAAC,OAAO,EAAE,KAAK,IAAI,EAAE;QAC9B,MAAM,IAAA,WAAK,EAAC;YACR,GAAG,EAAE,uBAAuB;YAC5B,KAAK,EAAE,EAAE;SACZ,EAAE,QAAQ,CAAC,CAAC;IACjB,CAAC,EAAE,EAAE,GAAG,mBAAa,CAAC,CAAC;IAEvB,YAAE,CAAC,UAAU,CAAC,uBAAuB,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,+BAA+B;YACpC,YAAY,EAAE,CAAC,YAAY,CAAC;YAC5B,KAAK,EAAE,EAAE;SACZ,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,IAAA,gBAAM,EAAC,GAAG,CAAC,SAAS,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;YACzC,KAAK,MAAM,IAAI,IAAI,GAAG,CAAC,IAAI,EAAE,CAAC;gBAC1B,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,IAAI,IAAI,CAAC,QAAQ,CAAC,SAAU,CAAC,CAAC;gBACnE,IAAA,gBAAM,EAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;YAChD,CAAC;QACL,CAAC;IACL,CAAC,EAAE,EAAE,GAAG,mBAAa,CAAC,CAAC;IAEvB,YAAE,CAAC,UAAU,CAAC,iDAAiD,EAAE,KAAK,IAAI,EAAE;QACxE,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,+BAA+B;YACpC,YAAY,EAAE,CAAC,4CAA4C,CAAC;YAC5D,cAAc,EAAE,IAAI;YACpB,KAAK,EAAE,EAAE;SACZ,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,IAAA,gBAAM,EAAC,GAAG,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC9B,IAAA,gBAAM,EAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,+BAA+B,CAAC,CAAC;QACjF,CAAC;IACL,CAAC,EAAE,EAAE,GAAG,mBAAa,CAAC,CAAC;IAEvB,YAAE,CAAC,UAAU,CAAC,uBAAuB,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,IAAA,WAAK,EAAC;YACR,GAAG,EAAE,uBAAuB;YAC5B,KAAK,EAAE,CAAC;YACR,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;IACjB,CAAC,EAAE,CAAC,GAAG,mBAAa,GAAG,CAAC,GAAG,IAAI,CAAC,CAAC;IAEjC,YAAE,CAAC,UAAU,CAAC,+BAA+B,EAAE,KAAK,IAAI,EAAE;QACtD,MAAM,GAAG,GAAG,MAAM,IAAA,gBAAU,EAAC;YACzB,GAAG,EAAE,uBAAuB;YAC5B,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;QAEb,MAAM,OAAO,GAAG,MAAM,IAAA,kBAAY,EAAC,QAAQ,CAAC,CAAC;QAE7C,IAAA,gBAAM,EAAC,OAAO,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,WAAW,EAAE,CAAC;QAEhE,MAAM,IAAA,6BAAuB,EAAC,GAAG,CAAC,EAAE,EAAE,QAAQ,CAAC,CAAC;QAEhD,MAAM,QAAQ,GAAG,MAAM,IAAA,kBAAY,EAAC,QAAQ,CAAC,CAAC;QAE9C,IAAA,gBAAM,EAAC,QAAQ,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,aAAa,EAAE,CAAC;IACvE,CAAC,EAAE,CAAC,GAAG,mBAAa,CAAC,CAAC;IAEtB,cAAc;IACd,qFAAqF;IACrF,gCAAgC;IAChC,wCAAwC;IACxC,oCAAoC;IACpC,+BAA+B;IAC/B,qBAAqB;IACrB,UAAU;IAEV,sCAAsC;IACtC,yBAAyB;IACzB,sDAAsD;IACtD,yCAAyC;IACzC,uHAAuH;IACvH,YAAY;IACZ,QAAQ;IACR,cAAc;IAEd,cAAc;IACd,4FAA4F;IAC5F,gCAAgC;IAChC,wCAAwC;IACxC,+BAA+B;IAC/B,gCAAgC;IAChC,qBAAqB;IACrB,UAAU;IACV,sCAAsC;IACtC,yBAAyB;IACzB,sDAAsD;IACtD,yCAAyC;IACzC,gIAAgI;IAChI,YAAY;IACZ,QAAQ;IACR,cAAc;IAEd,YAAE,CAAC,UAAU,CAAC,mCAAmC,EAAE,KAAK,IAAI,EAAE;QAC1D,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,uBAAuB;YAC5B,iBAAiB,EAAE,IAAI;YACvB,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,IAAA,gBAAM,EAAC,GAAG,CAAC,SAAS,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;QAC7C,CAAC;IACL,CAAC,EAAE,CAAC,GAAG,mBAAa,CAAC,CAAC;IAEtB,YAAE,CAAC,UAAU,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;QACnF,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,uBAAuB;YAC5B,kBAAkB,EAAE,KAAK;YACzB,iBAAiB,EAAE,IAAI;YACvB,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,IAAA,gBAAM,EAAC,GAAG,CAAC,SAAS,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;QAC7C,CAAC;IACL,CAAC,EAAE,CAAC,GAAG,mBAAa,CAAC,CAAC;IAEtB,YAAE,CAAC,UAAU,CAAC,yDAAyD,EAAE,KAAK,IAAI,EAAE;QAChF,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,uBAAuB;YAC5B,kBAAkB,EAAE,IAAI;YACxB,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,IAAA,gBAAM,EAAC,GAAG,CAAC,SAAS,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;QAC7C,CAAC;IACL,CAAC,EAAE,CAAC,GAAG,mBAAa,CAAC,CAAC;IAEtB,YAAE,CAAC,UAAU,CAAC,iCAAiC,EAAE,KAAK,IAAI,EAAE;QACxD,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,uBAAuB;YAC5B,eAAe,EAAE,IAAI;YACrB,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,IAAA,gBAAM,EAAC,GAAG,CAAC,SAAS,CAAC,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;QAC7C,CAAC;IACL,CAAC,EAAE,CAAC,GAAG,mBAAa,CAAC,CAAC;IAEtB,YAAE,CAAC,UAAU,CAAC,8CAA8C,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,GAAG,GAAG,MAAM,IAAA,WAAK,EAAC;YACpB,GAAG,EAAE,uBAAuB;YAC5B,eAAe,EAAE,KAAK;YACtB,KAAK,EAAE,CAAC;SACX,EAAE,QAAQ,CAAC,CAAC;QAEb,IAAA,gBAAM,EAAC,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/B,IAAI,GAAG,CAAC,OAAO,EAAE,CAAC;YACd,KAAK,MAAM,IAAI,IAAI,GAAG,CAAC,IAAI,EAAE,CAAC;gBAC1B,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,IAAI,IAAI,CAAC,QAAQ,CAAC,SAAU,CAAC,CAAC;gBACnE,IAAA,gBAAM,EAAC,GAAG,CAAC,QAAQ,CAAC,QAAQ,CAAC,eAAe,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC9D,CAAC;QACL,CAAC;IACL,CAAC,EAAE,CAAC,GAAG,mBAAa,CAAC,CAAC;AAC1B,CAAC,CAAC,CAAC","sourcesContent":["import { asyncCrawl, asyncCrawlWaitForFinish, crawl, crawlOngoing, Identity, idmux, scrapeTimeout } from \"./lib\";\nimport { describe, it, expect } from \"@jest/globals\";\n\nlet identity: Identity;\n\nbeforeAll(async () => {\n  identity = await idmux({\n    name: \"crawl\",\n    concurrency: 100,\n    credits: 1000000,\n  });\n}, 10000);\n\ndescribe(\"Crawl tests\", () => {\n    it.concurrent(\"works\", async () => {\n        await crawl({\n            url: \"https://firecrawl.dev\",\n            limit: 10,\n        }, identity);\n    }, 10 * scrapeTimeout);\n\n    it.concurrent(\"filters URLs properly\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev/pricing\",\n            includePaths: [\"^/pricing$\"],\n            limit: 10,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            expect(res.completed).toBeGreaterThan(0);\n            for (const page of res.data) {\n                const url = new URL(page.metadata.url ?? page.metadata.sourceURL!);\n                expect(url.pathname).toMatch(/^\\/pricing$/);\n            }\n        }\n    }, 10 * scrapeTimeout);\n\n    it.concurrent(\"filters URLs properly when using regexOnFullURL\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev/pricing\",\n            includePaths: [\"^https://(www\\\\.)?firecrawl\\\\.dev/pricing$\"],\n            regexOnFullURL: true,\n            limit: 10,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            expect(res.completed).toBe(1);\n            expect(res.data[0].metadata.sourceURL).toBe(\"https://firecrawl.dev/pricing\");\n        }\n    }, 10 * scrapeTimeout);\n\n    it.concurrent(\"delay parameter works\", async () => {\n        await crawl({\n            url: \"https://firecrawl.dev\",\n            limit: 3,\n            delay: 5,\n        }, identity);\n    }, 3 * scrapeTimeout + 3 * 5000);\n\n    it.concurrent(\"ongoing crawls endpoint works\", async () => {\n        const res = await asyncCrawl({\n            url: \"https://firecrawl.dev\",\n            limit: 3,\n        }, identity);\n\n        const ongoing = await crawlOngoing(identity);\n\n        expect(ongoing.crawls.find(x => x.id === res.id)).toBeDefined();\n\n        await asyncCrawlWaitForFinish(res.id, identity);\n\n        const ongoing2 = await crawlOngoing(identity);\n\n        expect(ongoing2.crawls.find(x => x.id === res.id)).toBeUndefined();\n    }, 3 * scrapeTimeout);\n    \n    // TEMP: Flaky\n    // it.concurrent(\"discovers URLs properly when origin is not included\", async () => {\n    //     const res = await crawl({\n    //         url: \"https://firecrawl.dev\",\n    //         includePaths: [\"^/blog\"],\n    //         ignoreSitemap: true,\n    //         limit: 10,\n    //     });\n\n    //     expect(res.success).toBe(true);\n    //     if (res.success) {\n    //         expect(res.data.length).toBeGreaterThan(1);\n    //         for (const page of res.data) {\n    //             expect(page.metadata.url ?? page.metadata.sourceURL).toMatch(/^https:\\/\\/(www\\.)?firecrawl\\.dev\\/blog/);\n    //         }\n    //     }\n    // }, 300000);\n    \n    // TEMP: Flaky\n    // it.concurrent(\"discovers URLs properly when maxDiscoveryDepth is provided\", async () => {\n    //     const res = await crawl({\n    //         url: \"https://firecrawl.dev\",\n    //         ignoreSitemap: true,\n    //         maxDiscoveryDepth: 1,\n    //         limit: 10,\n    //     });\n    //     expect(res.success).toBe(true);\n    //     if (res.success) {\n    //         expect(res.data.length).toBeGreaterThan(1);\n    //         for (const page of res.data) {\n    //             expect(page.metadata.url ?? page.metadata.sourceURL).not.toMatch(/^https:\\/\\/(www\\.)?firecrawl\\.dev\\/blog\\/.+$/);\n    //         }\n    //     }\n    // }, 300000);\n\n    it.concurrent(\"crawlEntireDomain parameter works\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev\",\n            crawlEntireDomain: true,\n            limit: 5,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            expect(res.completed).toBeGreaterThan(0);\n        }\n    }, 5 * scrapeTimeout);\n\n    it.concurrent(\"crawlEntireDomain takes precedence over allowBackwardLinks\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev\",\n            allowBackwardLinks: false,\n            crawlEntireDomain: true,\n            limit: 5,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            expect(res.completed).toBeGreaterThan(0);\n        }\n    }, 5 * scrapeTimeout);\n\n    it.concurrent(\"backward compatibility - allowBackwardLinks still works\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev\",\n            allowBackwardLinks: true,\n            limit: 5,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            expect(res.completed).toBeGreaterThan(0);\n        }\n    }, 5 * scrapeTimeout);\n\n    it.concurrent(\"allowSubdomains parameter works\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev\",\n            allowSubdomains: true,\n            limit: 5,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            expect(res.completed).toBeGreaterThan(0);\n        }\n    }, 5 * scrapeTimeout);\n\n    it.concurrent(\"allowSubdomains blocks subdomains when false\", async () => {\n        const res = await crawl({\n            url: \"https://firecrawl.dev\", \n            allowSubdomains: false,\n            limit: 5,\n        }, identity);\n\n        expect(res.success).toBe(true);\n        if (res.success) {\n            for (const page of res.data) {\n                const url = new URL(page.metadata.url ?? page.metadata.sourceURL!);\n                expect(url.hostname.endsWith(\"firecrawl.dev\")).toBe(true);\n            }\n        }\n    }, 5 * scrapeTimeout);\n});\n"]}