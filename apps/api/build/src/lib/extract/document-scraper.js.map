{"version":3,"file":"document-scraper.js","sourceRoot":"","sources":["../../../../src/lib/extract/document-scraper.ts"],"names":[],"mappings":";;AAiBA,wCAwFC;AAzGD,sDAA8F;AAE9F,gEAA8D;AAC9D,0DAAuD;AACvD,0DAAyD;AACzD,kDAAiD;AAY1C,KAAK,UAAU,cAAc,CAClC,OAA8B,EAC9B,SAAqB,EACrB,MAAc,EACd,wBAAgD,EAAE,eAAe,EAAE,KAAK,EAAE;IAE1E,MAAM,KAAK,GAAG,SAAS,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,OAAO,CAAC,GAAG,CAAC,CAAC;IAC3D,IAAI,KAAK,EAAE,CAAC;QACV,KAAK,CAAC,MAAM,GAAG,SAAS,CAAC;QACzB,KAAK,CAAC,MAAM,CAAC,SAAS,GAAG,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,CAAC;IACpD,CAAC;IAED,KAAK,UAAU,aAAa,CAAC,OAAe;QAC1C,MAAM,KAAK,GAAG,MAAM,CAAC,UAAU,EAAE,CAAC;QAClC,MAAM,WAAW,GAAG,MAAM,IAAA,6BAAc,EAAC;YACvC,OAAO,EAAE,OAAO,CAAC,MAAM;YACvB,YAAY,EAAE,EAAE;YAChB,YAAY,EAAE,IAAI;SACnB,CAAC,CAAC;QAEH,MAAM,IAAA,yBAAY,EAChB;YACE,GAAG,EAAE,OAAO,CAAC,GAAG;YAChB,IAAI,EAAE,aAAa;YACnB,OAAO,EAAE,OAAO,CAAC,MAAM;YACvB,aAAa,EAAE,qBAAa,CAAC,KAAK,CAAC;gBACjC,GAAG,qBAAqB;gBACxB,MAAM,EAAE,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,IAAI;aAC3B,CAAC;YACF,eAAe,EAAE;gBACf,MAAM,EAAE,OAAO,CAAC,MAAM;gBACtB,qBAAqB,EAAE,OAAO,CAAC,GAAG,CAAC,2BAA2B,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK;gBAC7E,aAAa,EAAE,IAAI;aACpB;YACD,MAAM,EAAE,OAAO,CAAC,MAAM;YACtB,SAAS,EAAE,IAAI;YACf,YAAY,EAAE,IAAI;YAClB,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE;YACrB,iBAAiB,EAAE,KAAK,EAAE,gBAAgB;SAC3C,EACD,EAAE,EACF,KAAK,EACL,WAAW,CACZ,CAAC;QAEF,MAAM,GAAG,GAAG,MAAM,IAAA,uBAAU,EAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAE7C,MAAM,IAAA,8BAAc,GAAE,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;QAErC,IAAI,KAAK,EAAE,CAAC;YACV,KAAK,CAAC,MAAM,CAAC,WAAW,GAAG,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,CAAC;YACpD,KAAK,CAAC,YAAY,GAAG;gBACnB,gBAAgB,EAAE,GAAG,CAAC,QAAQ,EAAE,MAAM,IAAI,CAAC;gBAC3C,sBAAsB,EAAE,GAAG,CAAC,QAAQ,EAAE,MAAM,IAAI,CAAC;gBACjD,UAAU,EAAE,CAAC;aACd,CAAC;QACJ,CAAC;QAED,OAAO,GAAG,CAAC;IACb,CAAC;IAED,IAAI,CAAC;QACH,IAAI,CAAC;YACH,MAAM,CAAC,KAAK,CAAC,sBAAsB,CAAC,CAAC;YACrC,MAAM,CAAC,GAAG,MAAM,aAAa,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;YAC/C,MAAM,CAAC,KAAK,CAAC,kBAAkB,CAAC,CAAC;YACjC,OAAO,CAAC,CAAC;QACX,CAAC;QAAC,OAAO,YAAY,EAAE,CAAC;YACtB,MAAM,CAAC,IAAI,CAAC,gBAAgB,EAAE,EAAE,KAAK,EAAE,YAAY,EAAE,CAAC,CAAC;YAEvD,IAAI,OAAO,CAAC,WAAW,EAAE,CAAC;gBACxB,iDAAiD;gBACjD,MAAM,CAAC,KAAK,CAAC,sBAAsB,CAAC,CAAC;gBACrC,MAAM,CAAC,GAAG,MAAM,aAAa,CAAC,OAAO,CAAC,OAAO,GAAG,CAAC,CAAC,CAAC;gBACnD,MAAM,CAAC,KAAK,CAAC,kBAAkB,CAAC,CAAC;gBACjC,OAAO,CAAC,CAAC;YACX,CAAC;YAED,MAAM,YAAY,CAAC;QACrB,CAAC;IACH,CAAC;IAAC,OAAO,KAAK,EAAE,CAAC;QACf,MAAM,CAAC,KAAK,CAAC,yBAAyB,EAAE,EAAE,KAAK,EAAE,CAAC,CAAC;QACnD,IAAI,KAAK,EAAE,CAAC;YACV,KAAK,CAAC,MAAM,GAAG,OAAO,CAAC;YACvB,KAAK,CAAC,KAAK,GAAG,KAAK,CAAC,OAAO,CAAC;QAC9B,CAAC;QACD,OAAO,IAAI,CAAC;IACd,CAAC;AACH,CAAC","sourcesContent":["import { Document, ScrapeOptions, URLTrace, scrapeOptions } from \"../../controllers/v1/types\";\nimport { logger } from \"../logger\";\nimport { getScrapeQueue } from \"../../services/queue-service\";\nimport { waitForJob } from \"../../services/queue-jobs\";\nimport { addScrapeJob } from \"../../services/queue-jobs\";\nimport { getJobPriority } from \"../job-priority\";\nimport type { Logger } from \"winston\";\nimport { getJobFromGCS } from \"../gcs-jobs\";\n\ninterface ScrapeDocumentOptions {\n  url: string;\n  teamId: string;\n  origin: string;\n  timeout: number;\n  isSingleUrl?: boolean;\n}\n\nexport async function scrapeDocument(\n  options: ScrapeDocumentOptions,\n  urlTraces: URLTrace[],\n  logger: Logger,\n  internalScrapeOptions: Partial<ScrapeOptions> = { onlyMainContent: false },\n): Promise<Document | null> {\n  const trace = urlTraces.find((t) => t.url === options.url);\n  if (trace) {\n    trace.status = \"scraped\";\n    trace.timing.scrapedAt = new Date().toISOString();\n  }\n\n  async function attemptScrape(timeout: number) {\n    const jobId = crypto.randomUUID();\n    const jobPriority = await getJobPriority({\n      team_id: options.teamId,\n      basePriority: 10,\n      from_extract: true,\n    });\n\n    await addScrapeJob(\n      {\n        url: options.url,\n        mode: \"single_urls\",\n        team_id: options.teamId,\n        scrapeOptions: scrapeOptions.parse({\n          ...internalScrapeOptions,\n          maxAge: 4 * 60 * 60 * 1000,\n        }),\n        internalOptions: {\n          teamId: options.teamId,\n          saveScrapeResultToGCS: process.env.GCS_FIRE_ENGINE_BUCKET_NAME ? true : false,\n          bypassBilling: true,\n        },\n        origin: options.origin,\n        is_scrape: true,\n        from_extract: true,\n        startTime: Date.now(),\n        zeroDataRetention: false, // not supported\n      },\n      {},\n      jobId,\n      jobPriority,\n    );\n\n    const doc = await waitForJob(jobId, timeout);\n\n    await getScrapeQueue().remove(jobId);\n\n    if (trace) {\n      trace.timing.completedAt = new Date().toISOString();\n      trace.contentStats = {\n        rawContentLength: doc.markdown?.length || 0,\n        processedContentLength: doc.markdown?.length || 0,\n        tokensUsed: 0,\n      };\n    }\n\n    return doc;\n  }\n\n  try {\n    try {\n      logger.debug(\"Attempting scrape...\");\n      const x = await attemptScrape(options.timeout);\n      logger.debug(\"Scrape finished!\");\n      return x;\n    } catch (timeoutError) {\n      logger.warn(\"Scrape failed.\", { error: timeoutError });\n\n      if (options.isSingleUrl) {\n        // For single URLs, try again with double timeout\n        logger.debug(\"Attempting scrape...\");\n        const x = await attemptScrape(options.timeout * 2);\n        logger.debug(\"Scrape finished!\");\n        return x;\n      }\n      \n      throw timeoutError;\n    }\n  } catch (error) {\n    logger.error(`error in scrapeDocument`, { error });\n    if (trace) {\n      trace.status = \"error\";\n      trace.error = error.message;\n    }\n    return null;\n  }\n}\n"]}