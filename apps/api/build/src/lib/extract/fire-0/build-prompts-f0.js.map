{"version":3,"file":"build-prompts-f0.js","sourceRoot":"","sources":["../../../../../src/lib/extract/fire-0/build-prompts-f0.ts"],"names":[],"mappings":";;AAAA,wDAeG;AAED,0DAaC;AAED,oEAOC;AAED,gEAEC;AAGD,kEAqBC;AAED,0EAOC;AAID,8EAEC;AAED,0EAKC;AAGD,4EAUC;AAED,gEAEC;AAGD,oEAIC;AAjHH,SAAgB,sBAAsB,CAAC,MAAc,EAAE,GAAW;IAC9D,OAAO,sKAAsK,GAAG;;sBAE9J,MAAM;;;;;;;;;;;sFAW0D,CAAC;AACrF,CAAC;AAED,SAAgB,uBAAuB,CACrC,MAA0B,EAC1B,MAAW,EACX,GAAW;IAEX,MAAM,YAAY,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;IACrD,OAAO;;YAEC,YAAY;YACZ,MAAM;iCACe,GAAG;;uNAEmL,CAAC;AACtN,CAAC;AAED,SAAgB,4BAA4B;IAC1C,OAAO;;;;;qJAK0I,CAAC;AACpJ,CAAC;AAED,SAAgB,0BAA0B,CAAC,WAAmB;IAC5D,OAAO,2GAA2G,WAAW,oVAAoV,CAAC;AACpd,CAAC;AAED,+BAA+B;AAC/B,SAAgB,2BAA2B;IACzC,OAAO;;;;;;;;;;;;;;;;;;;wOAmB6N,CAAC;AACvO,CAAC;AAED,SAAgB,+BAA+B,CAC7C,YAAoB,EACpB,MAAc,EACd,IAAc;IAEd,OAAO;YACC,YAAY,aAAa,MAAM,oBAAoB,IAAI,EAAE,CAAC;AACpE,CAAC;AAED,iBAAiB;AAEjB,SAAgB,iCAAiC;IAC/C,OAAO,oXAAoX,CAAC;AAC9X,CAAC;AAED,SAAgB,+BAA+B,CAC7C,MAAc,EACd,MAAW;IAEX,OAAO,iFAAiF,MAAM,qBAAqB,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,8BAA8B,CAAC;AAC1K,CAAC;AAED,gBAAgB;AAChB,SAAgB,gCAAgC,CAC9C,YAAoB,EACpB,iBAAsB,EACtB,KAAe;IAEf,OAAO,CACL,CAAC,YAAY,CAAC,CAAC,CAAC,GAAG,YAAY,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC;QACzC,ycAAyc,IAAI,CAAC,SAAS,CAAC,iBAAiB,CAAC,oGAAoG;QAC9kB,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CACjB,CAAC;AACJ,CAAC;AAED,SAAgB,0BAA0B,CAAC,MAAc;IACvD,OAAO,aAAa,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,KAAK,MAAM,EAAE,CAAC;AAC5D,CAAC;AAGD,SAAgB,4BAA4B,CAAC,MAAc;IACzD,OAAO;;sBAEW,MAAM,GAAG,CAAC;AAC9B,CAAC","sourcesContent":["export function buildRefrasedPrompt_F0(prompt: string, url: string): string {\n    return `You are a search query optimizer. Your task is to rephrase the following prompt into an effective search query that will find relevant results about this topic on ${url}.\n  \n  Original prompt: \"${prompt}\"\n  \n  Provide a rephrased search query that:\n  1. Maintains the core intent of the original prompt with ONLY the keywords\n  2. Uses relevant keywords\n  3. Is optimized for search engine results\n  4. Is concise and focused\n  5. Short is better than long\n  6. It is a search engine, not a chatbot\n  7. Concise\n  \n  Return only the rephrased search query, without any explanation or additional text.`;\n  }\n  \n  export function buildPreRerankPrompt_F0(\n    prompt: string | undefined,\n    schema: any,\n    url: string,\n  ): string {\n    const schemaString = JSON.stringify(schema, null, 2);\n    return `Create a concise search query that combines the key data points from both the schema and prompt. Focus on the core information needed while keeping it general enough to find relevant matches.\n  \n  Schema: ${schemaString}\n  Prompt: ${prompt}\n  Website to get content from: ${url}\n  \n  Return only a concise sentece or 2 focused on the essential data points that the user wants to extract. This will be used by an LLM to determine how releavant the links that are present are to the user's request.`;\n  }\n  \n  export function buildRerankerSystemPrompt_F0(): string {\n    return `You are a relevance expert scoring links from a website the user is trying to extract information from. Analyze the provided URLs and their content\n  to determine their relevance to the user's query and intent. \n      For each URL, assign a relevance score between 0 and 1, where 1\n       means highly relevant and we should extract the content from it and 0 means not relevant at all, we should not extract the content from it.\n        Always return all the links scored that you are giving. Do not omit links. \n       Always return the links in the same order they were provided. If the user wants the content from all the links, all links should be scored 1.`;\n  }\n  \n  export function buildRerankerUserPrompt_F0(searchQuery: string): string {\n    return `Given these URLs and their content, identify which ones are relevant to the user's extraction request: \"${searchQuery}\". Return an array of relevant links with their relevance scores (0-1). Higher scores should be given to URLs that directly address the user's extraction request. Be very mindful with the links you select, as if they are not that relevant it may affect the quality of the extraction. Only include URLs that have a relevancy score of 0.6+.`;\n  }\n  \n  // Multi entity schema anlayzer\n  export function buildAnalyzeSchemaPrompt_F0(): string {\n    return `You are a query classifier for a web scraping system. Classify the data extraction query as either:\n  A) Single-Answer: One answer across a few pages, possibly containing small arrays.\n  B) Multi-Entity: Many items across many pages, often involving large arrays.\n  \n  Consider:\n  1. Answer Cardinality: Single or multiple items?\n  2. Page Distribution: Found on 1-3 pages or many?\n  3. Verification Needs: Cross-page verification or independent extraction?\n  \n  Provide:\n  - Method: [Single-Answer/Multi-Entity]\n  - Confidence: [0-100%]\n  - Reasoning: Why this classification?\n  - Key Indicators: Specific aspects leading to this decision.\n  \n  Examples:\n  - \"Is this company a non-profit?\" -> Single-Answer\n  - \"Extract all product prices\" -> Multi-Entity\n  \n  For Single-Answer, arrays may be present but are typically small. For Multi-Entity, if arrays have multiple items not from a single page, return keys with large arrays. If nested, return the full key (e.g., 'ecommerce.products').`;\n  }\n  \n  export function buildAnalyzeSchemaUserPrompt_F0(\n    schemaString: string,\n    prompt: string,\n    urls: string[],\n  ): string {\n    return `Classify the query as Single-Answer or Multi-Entity. For Multi-Entity, return keys with large arrays; otherwise, return none:\n  Schema: ${schemaString}\\nPrompt: ${prompt}\\nRelevant URLs: ${urls}`;\n  }\n  \n  // Should Extract\n  \n  export function buildShouldExtractSystemPrompt_F0(): string {\n    return `You are a content relevance checker. Your job is to determine if the provided content is very relevant to extract information from based on the user's prompt. Return true only if the content appears relevant and contains information that could help answer the prompt. Return false if the content seems irrelevant or unlikely to contain useful information for the prompt.`;\n  }\n  \n  export function buildShouldExtractUserPrompt_F0(\n    prompt: string,\n    schema: any,\n  ): string {\n    return `Should the following content be used to extract information for this prompt: \"${prompt}\" User schema is: ${JSON.stringify(schema)}\\nReturn only true or false.`;\n  }\n  \n  // Batch extract\n  export function buildBatchExtractSystemPrompt_F0(\n    systemPrompt: string,\n    multiEntitySchema: any,\n    links: string[],\n  ): string {\n    return (\n      (systemPrompt ? `${systemPrompt}\\n` : \"\") +\n      `Always prioritize using the provided content to answer the question. Do not make up an answer. Do not hallucinate. In case you can't find the information and the string is required, instead of 'N/A' or 'Not speficied', return an empty string: '', if it's not a string and you can't find the information, return null. Be concise and follow the schema always if provided. If the document provided is not relevant to the prompt nor to the final user schema ${JSON.stringify(multiEntitySchema)}, return null. Here are the urls the user provided of which he wants to extract information from: ` +\n      links.join(\", \")\n    );\n  }\n  \n  export function buildBatchExtractPrompt_F0(prompt: string): string {\n    return `Today is: ${new Date().toISOString()}\\n${prompt}`;\n  }\n  \n  \n  export function buildRephraseToSerpPrompt_F0(prompt: string): string {\n    return `Rephrase the following prompt to be suitable for a search engine results page (SERP) query. Make sure the rephrased prompt is concise and focused on retrieving relevant search results:\n  \n  Original Prompt: \"${prompt}\"`;\n  }\n  "]}