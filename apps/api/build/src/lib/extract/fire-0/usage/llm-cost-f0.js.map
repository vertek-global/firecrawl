{"version":3,"file":"llm-cost-f0.js","sourceRoot":"","sources":["../../../../../../src/lib/extract/fire-0/usage/llm-cost-f0.ts"],"names":[],"mappings":";;AAaA,kEAIC;AAED,oDAIC;AAED,0CAmCC;AA3DD,mDAAgD;AAChD,2DAAuD;AAQvD,MAAM,iBAAiB,GAAG,CAAC,CAAC;AAC5B,MAAM,aAAa,GAAG,GAAG,CAAC;AAE1B,SAAgB,2BAA2B,CAAC,IAAS;IACnD,OAAO,IAAI,CAAC,KAAK,CACf,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC,MAAM,GAAG,iBAAiB,GAAG,aAAa,CAChE,CAAC;AACJ,CAAC;AAED,SAAgB,oBAAoB,CAAC,UAAwB;IAC3D,OAAO,UAAU,CAAC,MAAM,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE;QACxC,OAAO,KAAK,GAAG,eAAe,CAAC,KAAK,CAAC,CAAC;IACxC,CAAC,EAAE,CAAC,CAAC,CAAC;AACR,CAAC;AAED,SAAgB,eAAe,CAAC,UAAsB;IACpD,IAAI,SAAS,GAAG,CAAC,CAAC;IAClB,IAAI,CAAC;QACH,IAAI,KAAK,GAAG,UAAU,CAAC,KAAK,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,UAAU,IAAI,aAAa,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,0BAAW,CAAC,KAAK,CAAiB,CAAC;QAEnD,IAAI,CAAC,OAAO,EAAE,CAAC;YACb,eAAM,CAAC,KAAK,CAAC,2CAA2C,KAAK,EAAE,CAAC,CAAC;YACjE,OAAO,CAAC,CAAC;QACX,CAAC;QAED,IAAI,OAAO,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;YAC5B,eAAM,CAAC,KAAK,CAAC,SAAS,KAAK,sBAAsB,CAAC,CAAC;YACnD,OAAO,CAAC,CAAC;QACX,CAAC;QAED,qEAAqE;QACrE,IAAI,OAAO,CAAC,sBAAsB,EAAE,CAAC;YACnC,SAAS,IAAI,OAAO,CAAC,sBAAsB,CAAC;QAC9C,CAAC;QAED,wBAAwB;QACxB,IAAI,OAAO,CAAC,oBAAoB,EAAE,CAAC;YACjC,SAAS,IAAI,UAAU,CAAC,YAAY,GAAG,OAAO,CAAC,oBAAoB,CAAC;QACtE,CAAC;QAED,IAAI,OAAO,CAAC,qBAAqB,EAAE,CAAC;YAClC,SAAS,IAAI,UAAU,CAAC,gBAAgB,GAAG,OAAO,CAAC,qBAAqB,CAAC;QAC3E,CAAC;QAED,OAAO,MAAM,CAAC,SAAS,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;IACtC,CAAC;IAAC,OAAO,KAAK,EAAE,CAAC;QACf,eAAM,CAAC,KAAK,CAAC,0BAA0B,KAAK,EAAE,CAAC,CAAC;QAChD,OAAO,SAAS,CAAC;IACnB,CAAC;AACH,CAAC","sourcesContent":["import { TokenUsage } from \"../../../../controllers/v1/types\";\nimport { logger } from \"../../../../lib/logger\";\nimport { modelPrices } from \"../../usage/model-prices\";\n\ninterface ModelPricing {\n  input_cost_per_token?: number;\n  output_cost_per_token?: number;\n  input_cost_per_request?: number;\n  mode: string;\n}\nconst tokenPerCharacter = 4;\nconst baseTokenCost = 300;\n\nexport function calculateFinalResultCost_F0(data: any): number {\n  return Math.floor(\n    JSON.stringify(data).length / tokenPerCharacter + baseTokenCost,\n  );\n}\n\nexport function estimateTotalCost_F0(tokenUsage: TokenUsage[]): number {\n  return tokenUsage.reduce((total, usage) => {\n    return total + estimateCost_F0(usage);\n  }, 0);\n}\n\nexport function estimateCost_F0(tokenUsage: TokenUsage): number {\n  let totalCost = 0;\n  try {\n    let model = tokenUsage.model ?? (process.env.MODEL_NAME || \"gpt-4o-mini\");\n    const pricing = modelPrices[model] as ModelPricing;\n\n    if (!pricing) {\n      logger.error(`No pricing information found for model: ${model}`);\n      return 0;\n    }\n\n    if (pricing.mode !== \"chat\") {\n      logger.error(`Model ${model} is not a chat model`);\n      return 0;\n    }\n\n    // Add per-request cost if applicable (Only Perplexity supports this)\n    if (pricing.input_cost_per_request) {\n      totalCost += pricing.input_cost_per_request;\n    }\n\n    // Add token-based costs\n    if (pricing.input_cost_per_token) {\n      totalCost += tokenUsage.promptTokens * pricing.input_cost_per_token;\n    }\n\n    if (pricing.output_cost_per_token) {\n      totalCost += tokenUsage.completionTokens * pricing.output_cost_per_token;\n    }\n\n    return Number(totalCost.toFixed(7));\n  } catch (error) {\n    logger.error(`Error estimating cost: ${error}`);\n    return totalCost;\n  }\n}\n"]}