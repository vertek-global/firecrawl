{"version":3,"file":"llm-cost.js","sourceRoot":"","sources":["../../../../../src/lib/extract/usage/llm-cost.ts"],"names":[],"mappings":";;AAcA,sDAEC;AAED,4DAIC;AAED,8CAIC;AAED,oCAmCC;AAhED,gDAA6C;AAE7C,iDAA6C;AAQ7C,MAAM,iBAAiB,GAAG,GAAG,CAAC;AAC9B,MAAM,aAAa,GAAG,GAAG,CAAC;AAE1B,SAAgB,qBAAqB,CAAC,YAA0B;IAC9D,OAAO,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC,MAAM,EAAE,CAAC,SAAS,GAAG,KAAK,CAAC,CAAC;AAC5D,CAAC;AAED,SAAgB,wBAAwB,CAAC,IAAS;IAChD,OAAO,IAAI,CAAC,KAAK,CACf,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC,MAAM,GAAG,iBAAiB,GAAG,aAAa,CAChE,CAAC;AACJ,CAAC;AAED,SAAgB,iBAAiB,CAAC,UAAwB;IACxD,OAAO,UAAU,CAAC,MAAM,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE;QACxC,OAAO,KAAK,GAAG,YAAY,CAAC,KAAK,CAAC,CAAC;IACrC,CAAC,EAAE,CAAC,CAAC,CAAC;AACR,CAAC;AAED,SAAgB,YAAY,CAAC,UAAsB;IACjD,IAAI,SAAS,GAAG,CAAC,CAAC;IAClB,IAAI,CAAC;QACH,IAAI,KAAK,GAAG,UAAU,CAAC,KAAK,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,UAAU,IAAI,aAAa,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,0BAAW,CAAC,KAAK,CAAiB,CAAC;QAEnD,IAAI,CAAC,OAAO,EAAE,CAAC;YACb,eAAM,CAAC,KAAK,CAAC,2CAA2C,KAAK,EAAE,CAAC,CAAC;YACjE,OAAO,CAAC,CAAC;QACX,CAAC;QAED,IAAI,OAAO,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;YAC5B,eAAM,CAAC,KAAK,CAAC,SAAS,KAAK,sBAAsB,CAAC,CAAC;YACnD,OAAO,CAAC,CAAC;QACX,CAAC;QAED,qEAAqE;QACrE,IAAI,OAAO,CAAC,sBAAsB,EAAE,CAAC;YACnC,SAAS,IAAI,OAAO,CAAC,sBAAsB,CAAC;QAC9C,CAAC;QAED,wBAAwB;QACxB,IAAI,OAAO,CAAC,oBAAoB,EAAE,CAAC;YACjC,SAAS,IAAI,UAAU,CAAC,YAAY,GAAG,OAAO,CAAC,oBAAoB,CAAC;QACtE,CAAC;QAED,IAAI,OAAO,CAAC,qBAAqB,EAAE,CAAC;YAClC,SAAS,IAAI,UAAU,CAAC,gBAAgB,GAAG,OAAO,CAAC,qBAAqB,CAAC;QAC3E,CAAC;QAED,OAAO,MAAM,CAAC,SAAS,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;IACtC,CAAC;IAAC,OAAO,KAAK,EAAE,CAAC;QACf,eAAM,CAAC,KAAK,CAAC,0BAA0B,KAAK,EAAE,CAAC,CAAC;QAChD,OAAO,SAAS,CAAC;IACnB,CAAC;AACH,CAAC","sourcesContent":["import { TokenUsage } from \"../../../controllers/v1/types\";\nimport { logger } from \"../../../lib/logger\";\nimport { CostTracking } from \"../extraction-service\";\nimport { modelPrices } from \"./model-prices\";\n\ninterface ModelPricing {\n  input_cost_per_token?: number;\n  output_cost_per_token?: number;\n  input_cost_per_request?: number;\n  mode: string;\n}\nconst tokenPerCharacter = 0.5;\nconst baseTokenCost = 300;\n\nexport function calculateThinkingCost(costTracking: CostTracking): number {\n  return Math.ceil(costTracking.toJSON().totalCost * 20000);\n}\n\nexport function calculateFinalResultCost(data: any): number {\n  return Math.floor(\n    JSON.stringify(data).length / tokenPerCharacter + baseTokenCost,\n  );\n}\n\nexport function estimateTotalCost(tokenUsage: TokenUsage[]): number {\n  return tokenUsage.reduce((total, usage) => {\n    return total + estimateCost(usage);\n  }, 0);\n}\n\nexport function estimateCost(tokenUsage: TokenUsage): number {\n  let totalCost = 0;\n  try {\n    let model = tokenUsage.model ?? (process.env.MODEL_NAME || \"gpt-4o-mini\");\n    const pricing = modelPrices[model] as ModelPricing;\n\n    if (!pricing) {\n      logger.error(`No pricing information found for model: ${model}`);\n      return 0;\n    }\n\n    if (pricing.mode !== \"chat\") {\n      logger.error(`Model ${model} is not a chat model`);\n      return 0;\n    }\n\n    // Add per-request cost if applicable (Only Perplexity supports this)\n    if (pricing.input_cost_per_request) {\n      totalCost += pricing.input_cost_per_request;\n    }\n\n    // Add token-based costs\n    if (pricing.input_cost_per_token) {\n      totalCost += tokenUsage.promptTokens * pricing.input_cost_per_token;\n    }\n\n    if (pricing.output_cost_per_token) {\n      totalCost += tokenUsage.completionTokens * pricing.output_cost_per_token;\n    }\n\n    return Number(totalCost.toFixed(7));\n  } catch (error) {\n    logger.error(`Error estimating cost: ${error}`);\n    return totalCost;\n  }\n}\n"]}